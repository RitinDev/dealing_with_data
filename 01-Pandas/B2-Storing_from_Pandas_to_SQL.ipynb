{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/01-Pandas/B2-Storing_from_Pandas_to_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY3jQ0zMkInh"
      },
      "source": [
        "# A Minimal Example of Loading a Dataset to a Database"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U -q PyMySQL sqlalchemy sql_magic"
      ],
      "metadata": {
        "id": "wnFsH02TktVl",
        "outputId": "4a174dcd-5699-40ab-8352-bf1bf57f5f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 20.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 45.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 412 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Cv-hqc0kkInq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SFprbS3RkInv"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeIJwsNkInx"
      },
      "source": [
        "## Downloading Data and Putting in a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD' -o restaurants.csv"
      ],
      "metadata": {
        "id": "M1zK8hb7kbvS",
        "outputId": "4cdb6876-d4e5-4fe7-8754-dcdeecf4b436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  103M    0  103M    0     0  6475k      0 --:--:--  0:00:16 --:--:-- 6779k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yr611YQJkInz"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file\n",
        "df = pd.read_csv('restaurants.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding underscores in all column names\n",
        "cols = df.columns\n",
        "cols = cols.map(lambda x: x.replace(' ', '_').upper())\n",
        "df.columns = cols"
      ],
      "metadata": {
        "id": "D3BEnpDwmpvv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Q5wGqcEUkIn0"
      },
      "outputs": [],
      "source": [
        "# Some bookkeeping regarding datatypes\n",
        "df[\"INSPECTION_DATE\"] = pd.to_datetime(df[\"INSPECTION_DATE\"], format=\"%m/%d/%Y\")\n",
        "df[\"SCORE\"] = pd.to_numeric(df[\"SCORE\"])\n",
        "\n",
        "# Delete useless columns\n",
        "df = df.drop(['GRADE_DATE', 'RECORD_DATE', 'LOCATION_POINT'], axis='columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create MySQL Connection"
      ],
      "metadata": {
        "id": "9QqKfQZ2ky4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Connect to the MySQL, and use the \"public\" database\n",
        "conn_string = 'mysql+pymysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(\n",
        "    user     = 'student', \n",
        "    password = 'dwdstudent2015', \n",
        "    host     = 'db.ipeirotis.org', \n",
        "    port     = 3306, \n",
        "    encoding = 'utf-8',\n",
        "    db = 'public'\n",
        ")\n",
        "engine = create_engine(conn_string)"
      ],
      "metadata": {
        "id": "EbklRLuakklS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the table for storing the data\n",
        "\n",
        "Although we can let Pandas create the table automatically, the choice of data types of not always great. It is better to manually define the data types for the database."
      ],
      "metadata": {
        "id": "1V74LuxWqz-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the maximum string lengths for \n",
        "# the textual attributes. Useful when creating\n",
        "# a table in SQL.\n",
        "for c in df.columns.values:\n",
        "  if df.dtypes[c] == 'object': \n",
        "    print(c, df[c].str.len().max())\n"
      ],
      "metadata": {
        "id": "Qf0Tld8TrGVo",
        "outputId": "342fb246-b885-41d7-c7ae-91e1526d0365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DBA 95.0\n",
            "BORO 13\n",
            "BUILDING 10.0\n",
            "STREET 40.0\n",
            "PHONE 12.0\n",
            "CUISINE_DESCRIPTION 30.0\n",
            "ACTION 130.0\n",
            "VIOLATION_CODE 5.0\n",
            "VIOLATION_DESCRIPTION 940.0\n",
            "CRITICAL_FLAG 14\n",
            "GRADE 1.0\n",
            "INSPECTION_TYPE 59.0\n",
            "NTA 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To avoid conflicts between people writing in the same database, we add a random suffix in the tables\n",
        "# We only create the variable once while running the notebook\n",
        "import uuid\n",
        "if \"suffix\" not in globals():\n",
        "    suffix = str(uuid.uuid4())[:8]\n",
        "print(suffix)"
      ],
      "metadata": {
        "id": "DWSlYTpc7agA",
        "outputId": "25c3c58b-82ee-4349-c50b-c5854356f338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eafad2fa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MySQL database that we will use to store the table\n",
        "db_name = \"public\"\n",
        "\n",
        "# The name f the table that we will use\n",
        "table_name = f\"inspections_{suffix}\""
      ],
      "metadata": {
        "id": "yQ76Iioe7nQw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PFDaggHLkIn2",
        "outputId": "4d387b03-fd95-4336-c8df-42a6f2d110c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7f6454370cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "drop_table_sql = f'''\n",
        "DROP TABLE IF EXISTS {db_name}.{table_name};\n",
        "'''\n",
        "engine.execute(drop_table_sql)\n",
        "\n",
        "\n",
        "create_table_sql = f'''\n",
        "CREATE TABLE IF NOT EXISTS {db_name}.{table_name} (\n",
        "    CAMIS CHAR(8),\n",
        "    DBA VARCHAR(100),\n",
        "    BUILDING VARCHAR(10),\n",
        "    STREET VARCHAR(40),\n",
        "    ZIPCODE CHAR(5),\n",
        "    BORO VARCHAR(15),\n",
        "    PHONE CHAR(12),\n",
        "    CUISINE_DESCRIPTION VARCHAR(30),\n",
        "    LATITUDE FLOAT,\n",
        "    LONGITUDE FLOAT,\n",
        "    COMMUNITY_BOARD CHAR(3),\n",
        "    COUNCIL_DISTRICT CHAR(2),\n",
        "    CENSUS_TRACT CHAR(6),\n",
        "    BIN CHAR(7),\n",
        "    BBL CHAR(10),\n",
        "    NTA CHAR(4),\n",
        "    INSPECTION_DATE DATETIME,\n",
        "    ACTION VARCHAR(130),\n",
        "    GRADE CHAR(1),\n",
        "    INSPECTION_TYPE VARCHAR(60),\n",
        "    VIOLATION_CODE VARCHAR(10),\n",
        "    VIOLATION_DESCRIPTION VARCHAR(1000),\n",
        "    CRITICAL_FLAG VARCHAR(15),\n",
        "    SCORE SMALLINT\n",
        ")  ENGINE=INNODB DEFAULT CHARSET=UTF8MB4;\n",
        "'''\n",
        "engine.execute(create_table_sql)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert data to DB using the `to_sql` command"
      ],
      "metadata": {
        "id": "K3TNb60isD1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the dataframe as a SQL table, using the to_sql command\n",
        "df.to_sql(name=table_name, # name of the table\n",
        "                   con=engine, # use the connection to MySQL created earlier\n",
        "                   if_exists='append', # we created the empty table above\n",
        "                   index=False, # do not write the index column in the database\n",
        "                   chunksize=1000 # write 1000 lines at a time\n",
        ")"
      ],
      "metadata": {
        "id": "wUsiP9Gto9qK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1tX_xYUkIn8"
      },
      "outputs": [],
      "source": [
        "# And then we can just retrieve it from the database\n",
        "r = pd.read_sql(f\"SELECT * FROM public.{table_name} LIMIT 100\", con=engine)\n",
        "r.head(100)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "B2-Pandas_and_SQL-Inserting_Data.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}